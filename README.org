#+BEGIN_HTML
<a href="https://travis-ci.org/bozenne/lavaSearch2"><img src="https://travis-ci.org/bozenne/lavaSearch2.svg?branch=master"></a>
#+END_HTML

* lavaSeach2

** Overview

*lava* is an R package that implements Structural Equation Models with
 latent variables (see [[https://github.com/kkholst/lava]]). The present
 software package, *lavaSearch2*, provides additional functionalities
 to the *lava* package when using maximum likelihood estimation. The
 main functionalities are:
- Improved control of the type 1 error rate when performing inference
  in small samples. Also applicable to specific =gls= and =lme= models
  (*nlme* package).
- Adjustment for multiple comparisons when performing inference using
  several latent variable models.
- Improved detection of local dependencies that are not included in
  the latent variable model. Also applicable to Cox models via the
  libraries *riskRegression* and *survival* / *rms*.

_Limitations_: *lavaSearch2* has been design for Gaussian latent variable
models with complete data. This means that it may not work / give valid results:
- in presence of missing values. Note: this case could probably be fixed,
  you can contact the package maintainer if you need this functionality.
- in presence of censored or binary outcomes.
- with stratified models (i.e. object of class =multigroup=). Note:
  this case could probably be fixed, you can contact the package
  maintainer if you need this functionality.

** Installation 
Install the stable version from CRAN using:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
install.packages("lavaSearch2")
#+END_SRC

Install the development version from Github using:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
devtools::install_github("bozenne/lavaSearch2")
#+END_SRC

** Functionalities

Load *lavaSearch2* in the R session:
#+BEGIN_SRC R :exports code :results output :session *R* :cache no
suppressPackageStartupMessages(library(lavaSearch2))
#+END_SRC 

#+RESULTS:


*** Inference with small samples

Using *lava*, the p.values that are obtained from the summary (Wald
tests) rely on a Gaussian approximation. While being asymptotically
valid, this approximation may not provide a very accurate control of
the type 1 error rate in small samples. Simulations have shown that
the type 1 error rate tends to be too large, i.e. the p.values are have
a downward bias.

*lavaSearch2* improves the Gaussian approximation in two way:
- using a Student's t distribution instead of a normal distribution to
  account for the uncertainty on the variance of the parameters. The
  degrees of freedom are estimated using Satterwaite approximation,
  i.e. identifying the chi-squared distribution that best fit the
  observed moments of the variance of the parameters.
- remove the first order bias in the residual variance due to the
  Maximum Likelihood. This bias also affects the standard error of the
  estimates and the control of the type 1 error. The correction does
  not change the estimates (i.e. the column "Estimate" in the summary
  remain unchanged), but it changes the corresponding standard error
  and degree of freedoms (i.e. columns "Std. Error" and "df" in the
  summary are modified).


Let's see an example. First, we simulate some data:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
## simulate data
mSim <- lvm(Y[1:1]~0.3*X1+0.2*X2)
set.seed(10)
df.data <- sim(mSim, 2e1)

## display
head(df.data)
#+END_SRC

#+RESULTS:
:             Y         X1          X2
: 1  1.05716326 -0.5963106  1.08655140
: 2  0.00765243 -2.1852868 -0.76254488
: 3 -0.73952284 -0.6748659 -0.82866254
: 4 -0.06799129 -2.1190612  0.83447390
: 5  0.72145532 -1.2651980 -0.96765199
: 6  1.27193277 -0.3736616 -0.02881534

Then we fit the latent variable model:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
m <- lvm(Y~X1+X2)
e <- estimate(m, data = df.data)
#+END_SRC

#+RESULTS:

The class of the resulting object is =lvmfit=:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
class(e)
#+END_SRC

#+RESULTS:
: [1] "lvmfit"

We can extract the Wald tests based on a normal approximation using
=summary=:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
summary(e)$coef
#+END_SRC

#+RESULTS:
:       Estimate Std. Error   Z-value      P-value
: Y~X1 0.1550938  0.2032984 0.7628877 0.4455303456
: Y~X2 0.4581556  0.2025335 2.2621221 0.0236898575
: Y~~Y 0.5557910  0.1757566 3.1622777           NA
: Y    0.7967775  0.2311125 3.4475747 0.0005656439


To activate the functionalities of *lavaSearch2* one needs first to
 call =sCorrect= (i.e. Satterthwaite correction) to update the
 object. Two small sample corrections are implemented:
- the Satterthwaite correction
- the Satterthwaite correction with a bias correction for the
  variance-covariance matrix of the coefficients. This correction is
  inspired from the Kenward-Roger correction in mixed models.

When calling =sCorrect=, the right hand side indicates whether the
  bias correction should be used or not.
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
sCorrect(e) <- TRUE ## with biais correction
#+END_SRC

#+RESULTS:

=sCorrect= pre-computes quantities necessary for the small sample
correction (e.g. the derivative of the variance-covariance matrix) and
store them in the object. =sCorrect= also adds the class =lvmfit2= to
the object:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
class(e)
#+END_SRC
#+RESULTS:
: [1] "lvmfit2" "lvmfit"

Then p-values computed using the small sample correction can be
obtained calling the =summary= method, as usual:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
summary(e)$coef
#+END_SRC

#+RESULTS:
:       Estimate Std. Error   t-value     P-value    df
: Y~X1 0.1550938  0.2180132 0.7113965 0.486486336 17.00
: Y~X2 0.4581556  0.2171930 2.1094398 0.050036443 17.00
: Y~~Y 0.5557910  0.2192300 2.5351965          NA  4.25
: Y    0.7967775  0.2478405 3.2148800 0.005082163 17.00

*** Inference using F-tests

The function =compare2= can be use to perform F-test, i.e. to test
simultaneously several linear combinations of the coefficients.
=compare2= uses a contrast matrix to encode in lines which linear
combination of coefficients should be tested. For instance if we want
to simultaneously test whether all the mean coefficients are 0, we can
create a contrast matrix using =createContrast=:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
resC <- createContrast(e, par = c("Y=0","Y~X1=0","Y~X2=0"))
resC
#+END_SRC

#+RESULTS:
#+begin_example
$contrast
           Y Y~X1 Y~X2 Y~~Y
[Y] = 0    1    0    0    0
[Y~X1] = 0 0    1    0    0
[Y~X2] = 0 0    0    1    0

$null
   [Y] = 0 [Y~X1] = 0 [Y~X2] = 0 
         0          0          0 

$Q
[1] 3
#+end_example

We can then test the linear hypothesis by specifying in =compare2= the
left hand side of the hypothesis (argument contrast) and the right
hand side (argument null):
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
resTest <- compare2(e, contrast = resC$contrast, null = resC$null)
resTest
#+END_SRC

#+RESULTS:
#+begin_example

	- Wald test -

	Null Hypothesis:
	[Y] = 0
	[Y~X1] = 0
	[Y~X2] = 0

data:  
F-statistic = 7.5759, df1 = 3, df2 = 17, p-value = 0.001982
sample estimates:
            Estimate   Std.Err df          2.5%     97.5%
[Y] = 0    0.7967775 0.2478405 17  2.738798e-01 1.3196753
[Y~X1] = 0 0.1550938 0.2180132 17 -3.048738e-01 0.6150615
[Y~X2] = 0 0.4581556 0.2171930 17 -8.162049e-05 0.9163928
#+end_example

The same result could have been obtained using the par argument to
define the linear hypothesis:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
resTest2 <- compare2(e, par = c("Y","Y~X1","Y~X2"))
identical(resTest,resTest2)
#+END_SRC

#+RESULTS:
: [1] TRUE

*** Inference: adjustment for multiple comparisons (single model)

When performing multiple testing, adjustment for multiple comparisons
is necessary in order to control the type 1 error rate, i.e. to
provide interpretable p.values. The *multcomp* package enables to do
such adjustment when all tests comes from the same =lvmfit= object:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
suppressPackageStartupMessages(library(multcomp))

## simulate data
mSim <- lvm(Y ~ 0.25 * X1 + 0.3 * X2 + 0.35 * X3 + 0.4 * X4 + 0.45 * X5 + 0.5 * X6)
set.seed(10)
df.data <- sim(mSim, n = 4e1)

## fit lvm
e.lvm <- estimate(lvm(Y ~ X1 + X2 + X3 + X4 + X5 + X6), data = df.data)
name.coef <- names(coef(e.lvm))
n.coef <- length(name.coef)

## Create contrast matrix
resC <- createContrast(e.lvm, par = paste0("Y~X",1:6))
resC$contrast
#+END_SRC

#+RESULTS:
:            Y Y~X1 Y~X2 Y~X3 Y~X4 Y~X5 Y~X6 Y~~Y
: [Y~X1] = 0 0    1    0    0    0    0    0    0
: [Y~X2] = 0 0    0    1    0    0    0    0    0
: [Y~X3] = 0 0    0    0    1    0    0    0    0
: [Y~X4] = 0 0    0    0    0    1    0    0    0
: [Y~X5] = 0 0    0    0    0    0    1    0    0
: [Y~X6] = 0 0    0    0    0    0    0    1    0

#+BEGIN_SRC R :exports both :results output :session *R* :cache no
e.glht <- glht(e.lvm, linfct = resC$contrast, rhs = resC$null)
summary(e.glht)
#+END_SRC
#+RESULTS:
#+begin_example

	 Simultaneous Tests for General Linear Hypotheses

Fit: estimate.lvm(x = lvm(Y ~ X1 + X2 + X3 + X4 + X5 + X6), data = df.data)

Linear Hypotheses:
                Estimate Std. Error z value Pr(>|z|)   
[Y~X1] = 0 == 0   0.3270     0.1589   2.058  0.20725   
[Y~X2] = 0 == 0   0.4025     0.1596   2.523  0.06611 . 
[Y~X3] = 0 == 0   0.5072     0.1383   3.669  0.00144 **
[Y~X4] = 0 == 0   0.3161     0.1662   1.902  0.28582   
[Y~X5] = 0 == 0   0.3875     0.1498   2.586  0.05554 . 
[Y~X6] = 0 == 0   0.3758     0.1314   2.859  0.02482 * 
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
(Adjusted p values reported -- single-step method)
#+end_example

Note that this correction relies on the Gaussian approximation. To use
small sample corrections implemented in *lavaSearch2*, just call
=glht2= instead of =glht=:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
e.glht2 <- glht2(e.lvm, linfct = resC$contrast, rhs = resC$null)
summary(e.glht2)
#+END_SRC

#+RESULTS:
#+begin_example

	 Simultaneous Tests for General Linear Hypotheses

Fit: estimate.lvm(x = lvm(Y ~ X1 + X2 + X3 + X4 + X5 + X6), data = df.data)

Linear Hypotheses:
          Estimate Std. Error t value Pr(>|t|)  
Y~X1 == 0   0.3270     0.1723   1.898   0.3130  
Y~X2 == 0   0.4025     0.1730   2.327   0.1375  
Y~X3 == 0   0.5072     0.1499   3.385   0.0107 *
Y~X4 == 0   0.3161     0.1802   1.754   0.3960  
Y~X5 == 0   0.3875     0.1624   2.385   0.1216  
Y~X6 == 0   0.3758     0.1425   2.637   0.0694 .
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
(Adjusted p values reported -- single-step method)
#+end_example

The single step method is the appropriate correction when one wants to
report the most significant p-value relative to a set of
hypotheses. If the second most significant p-value is also to be
reported then the method "free" is more appropriate:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
summary(e.glht2, test = adjusted("free"))
#+END_SRC

#+RESULTS:
#+begin_example

	 Simultaneous Tests for General Linear Hypotheses

Fit: estimate.lvm(x = lvm(Y ~ X1 + X2 + X3 + X4 + X5 + X6), data = df.data)

Linear Hypotheses:
          Estimate Std. Error t value Pr(>|t|)  
Y~X1 == 0   0.3270     0.1723   1.898   0.1219  
Y~X2 == 0   0.4025     0.1730   2.327   0.0842 .
Y~X3 == 0   0.5072     0.1499   3.385   0.0107 *
Y~X4 == 0   0.3161     0.1802   1.754   0.1219  
Y~X5 == 0   0.3875     0.1624   2.385   0.0842 .
Y~X6 == 0   0.3758     0.1425   2.637   0.0587 .
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
(Adjusted p values reported -- free method)
#+end_example
Indeed, here there is no relations between the hypotheses. See the
book: "Multiple Comparisons Using R" by Frank Bretz, Torsten Hothorn,
and Peter Westfall (2011, CRC Press) for details about the theory
underlying the *multcomp* package.

*** Inference: adjustment for multiple comparisons (multiple models)

Pipper et al. in "A Versatile Method for Confirmatory Evaluation of
the Effects of a Covariate in Multiple Models" (2012, Journal of the
Royal Statistical Society, Series C) developed a method to assess the
effect of an exposure on several outcomes when a different model is
fitted for each outcome. This method has been implemented in the =mmm=
function from the *multcomp* package for glm and Cox
models. *lavaSearch2* extends it to =lvm=. 

Let's consider an example where we wish to assess the treatment effect
on three outcomes X, Y, and Z. We have at hand three measurements
relative to outcome Z for each individual:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
mSim <- lvm(X ~ Age + 0.5*Treatment,
            Y ~ Gender + 0.25*Treatment,
            c(Z1,Z2,Z3) ~ eta, eta ~ 0.75*treatment,
            Age[40:5]~1)
latent(mSim) <- ~eta
categorical(mSim, labels = c("placebo","SSRI")) <- ~Treatment
categorical(mSim, labels = c("male","female")) <- ~Gender

n <- 5e1
set.seed(10)
df.data <- sim(mSim, n = n, latent = FALSE)
head(df.data)
#+END_SRC

#+RESULTS:
:          X      Age Treatment          Y Gender         Z1         Z2          Z3  treatment
: 1 39.12289 39.10415   placebo  0.6088958 female  1.8714112  2.2960633 -0.09326935  1.1639675
: 2 39.56766 39.25191      SSRI  1.0001325 female  0.9709943  0.6296226  1.31035910 -1.5233846
: 3 41.68751 43.05884   placebo  2.1551047 female -1.1634011 -0.3332927 -1.30769267 -2.5183351
: 4 44.68102 44.78019      SSRI  0.3852728 female -1.0305476  0.6678775  0.99780139 -0.7075292
: 5 41.42559 41.13105   placebo -0.8666783   male -1.6342816 -0.8285492  1.20450488 -0.2874329
: 6 42.64811 41.75832      SSRI -1.0710170 female -1.2198019 -1.9602130 -1.85472132 -0.4353083

We fit a model specific to each outcome:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
lmX <- lm(X ~ Age + Treatment, data = df.data)
lvmY <- estimate(lvm(Y ~ Gender + Treatment), data = df.data)
lvmZ <- estimate(lvm(c(Z1,Z2,Z3) ~ 1*eta, eta ~ -1 + Treatment), 
                 data = df.data)
#+END_SRC

#+RESULTS:

and combine them into a list of =lvmfit= objects:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
mmm.lvm <- mmm(X = lmX, Y = lvmY, Z = lvmZ)
#+END_SRC

#+RESULTS:

We can then generate a contrast matrix to test each coefficient
related to the treatment:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
resC <- createContrast(mmm.lvm, var.test = "Treatment", add.variance = TRUE)
resC$contrast
#+END_SRC

#+RESULTS:
:                      X: (Intercept) X: Age X: TreatmentSSRI X: sigma2 Y: Y Y: Y~Genderfemale Y: Y~TreatmentSSRI Y: Y~~Y Z: Z1 Z: Z2 Z: Z3 Z: eta~TreatmentSSRI
: X: TreatmentSSRI                  0      0                1         0    0                 0                  0       0     0     0     0                    0
: Y: Y~TreatmentSSRI                0      0                0         0    0                 0                  1       0     0     0     0                    0
: Z: eta~TreatmentSSRI              0      0                0         0    0                 0                  0       0     0     0     0                    1
:                      Z: Z1~~Z1 Z: Z2~~Z2 Z: Z3~~Z3 Z: eta~~eta
: X: TreatmentSSRI             0         0         0           0
: Y: Y~TreatmentSSRI           0         0         0           0
: Z: eta~TreatmentSSRI         0         0         0           0

#+BEGIN_SRC R :exports both :results output :session *R* :cache no
lvm.glht2 <- glht2(mmm.lvm, linfct = resC$contrast, rhs = resC$null)
summary(lvm.glht2)
#+END_SRC

#+RESULTS:
: 
: 	 Simultaneous Tests for General Linear Hypotheses
: 
: Linear Hypotheses:
:                           Estimate Std. Error t value Pr(>|t|)
: X: TreatmentSSRI == 0       0.4661     0.2528   1.844    0.186
: Y: Y~TreatmentSSRI == 0    -0.5421     0.2609  -2.078    0.116
: Z: eta~TreatmentSSRI == 0  -0.6198     0.4400  -1.409    0.393
: (Adjusted p values reported -- single-step method)

This can be compared to the unadjusted p.values:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
summary(lvm.glht2, test = univariate())
#+END_SRC

#+RESULTS:
#+begin_example

	 Simultaneous Tests for General Linear Hypotheses

Linear Hypotheses:
                          Estimate Std. Error t value Pr(>|t|)  
X: TreatmentSSRI == 0       0.4661     0.2528   1.844   0.0715 .
Y: Y~TreatmentSSRI == 0    -0.5421     0.2609  -2.078   0.0432 *
Z: eta~TreatmentSSRI == 0  -0.6198     0.4400  -1.409   0.1656  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
(Univariate p values reported)
#+end_example

*** Model diagnostic: detection of local dependencies

The =modelsearch= function of *lava* is a diagnostic tool for latent
variable models. It enables to search for local dependencies
(i.e. model misspecification) and add them to the model. Obviously it
is a data-driven procedure and its usefulness can be discussed,
especially in small samples:
- the procedure is instable, i.e. is likely to lead to two different
  models when applied on two different dataset sampled from the same
  generative model.
- it is hard to define a meaningful significance threshold since
  p-values should be adjusted for multiple comparisons and sequential
  testing. However traditional methods like Bonferonni-Holm tend to
  over corrected and therefore reduce the power of the procedure since
  they assume that the test are independent.

The function =modelsearch2= in *lavaSearch2* partially solves the
second issue by adjusting the p-values for multiple testing.

Let's see an example:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
## simulate data
mSim <- lvm(c(y1,y2,y3)~u, u~x1+x2)
latent(mSim) <- ~u
covariance(mSim) <- y2~y3
transform(mSim, Id~u) <- function(x){1:NROW(x)}
set.seed(10)
df.data <- lava::sim(mSim, n = 125, latent = FALSE)
head(df.data)
#+END_SRC

#+RESULTS:
:           y1           y2         y3         x1         x2 Id
: 1  5.5071523  4.883752014  6.2928016  0.8694750  2.3991549  1
: 2 -0.6398644  0.025832617  0.5088030 -0.6800096 -0.0898721  2
: 3 -2.5835495 -2.616715027 -2.8982645  0.1732145 -0.8216484  3
: 4 -2.5312637 -2.518185427 -2.9015033 -0.1594380 -0.2869618  4
: 5  1.6346220 -0.001877577  0.3705181  0.7934994  0.1312789  5
: 6  0.4939972  1.759884014  1.5010499  1.6943505 -1.0620840  6

#+BEGIN_SRC R :exports both :results output :session *R* :cache no
## fit model
m <- lvm(c(y1,y2,y3)~u, u~x1)
latent(m) <- ~u
addvar(m) <- ~x2 
e.lvm <- estimate(m, data = df.data)
#+END_SRC

#+RESULTS:

=modelsearch2= can be used to sequentially apply the =modelsearch=
function with a given correction for the p.values:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
resScore <- modelsearch2(e.lvm, statistic = "score", method.p.adjust = "holm",
                         alpha = 0.1, trace = FALSE)
summary(resScore)
#+END_SRC

#+RESULTS:
: Sequential search for local dependence using the score statistic 
:  The variable selection procedure retained 3 variables:
:      link nTests noConvergence statistic adjusted.p.value
: 10   u~x2     10             0 36.436487     1.577228e-08
: 5  y2~~y3      9             0  6.912568     7.703278e-02
: 7   y3~x1      8             0  3.136431     6.124895e-01
: confidence level: 0.9 (two sided, adjustement: holm)

This indeed matches the highest score statistic found by
=modelsearch=:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
resScore0 <- modelsearch(e.lvm, silent = TRUE)
max(resScore0$test[,"Test Statistic"])
#+END_SRC

#+RESULTS:
: [1] 36.43649

To adjust for multiple comparisons, the argument statistic needs to be
set to =Wald=. Setting the argument =method.p.adjust= to =max= enable
an appropriate adjustment of the p.values for multiple comparisons:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
resMax <- modelsearch2(e.lvm, statistic = "Wald", method.p.adjust = "max",
                       alpha = 0.1, trace = FALSE)
summary(resMax)
#+END_SRC

#+RESULTS:
: Sequential search for local dependence using the Wald statistic 
:  The variable selection procedure retained 3 variables:
:      link nTests noConvergence statistic adjusted.p.value quantile
: 10   u~x2     10             0  6.772351     1.258976e-09 2.427734
: 5  y2~~y3      9             0  2.582396     6.946423e-02 2.436287
: 7   y3~x1      8             0  1.813579     2.696723e-01 2.296602
: confidence level: 0.9 (two sided, adjustement: max)

We can compare the adjustment using the max distribution to bonferroni:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
c(bonferroni =  min(p.adjust(resMax$sequenceTest[[2]][,"p.value"], method = "bonferroni")),
  max = min(resMax$sequenceTest[[2]][,"adjusted.p.value"]))
#+END_SRC

#+RESULTS:
: bonferroni        max 
: 0.08830535 0.06946423

Here the difference is small because the generative model did not
include an unknown correlation structure. Because it can be time
consuming to compute the exact p-values, an approximation could be to
only compute them when no p-value passes the bonferroni correction at
a given step. The is what the option =fastmax= does:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
resMax2 <- modelsearch2(e.lvm, statistic = "Wald", method.p.adjust = "fastmax",
                        alpha = 0.1, trace = FALSE)
summary(resMax2)
#+END_SRC

#+RESULTS:
: Sequential search for local dependence using the Wald statistic 
:  The variable selection procedure retained 3 variables:
:      link nTests noConvergence statistic adjusted.p.value
: 10   u~x2     10             0  6.772351       0.00000000
: 5  y2~~y3      9             0  2.582396       0.06999172
: 7   y3~x1      8             0  1.813579       0.27069600
: confidence level: 0.9 (two sided, adjustement: fastmax)

*** Model diagnostic: checking that the names of the variables in the model match those of the data

When estimating latent variable models using *lava*, it sometimes
happens that the model does not converge:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
## simulate data
set.seed(10)
df.data <- sim(lvm(Y~X1+X2), 1e2)

## fit model
mWrong <- lvm(Y ~ X + X2)
eWrong <- estimate(mWrong, data = df.data)
#+END_SRC

#+RESULTS:
: Warning messages:
: 1: In estimate.lvm(mWrong, data = df.data) :
:   Lack of convergence. Increase number of iteration or change starting values.
: 2: In sqrt(diag(asVar)) : NaNs produced

 This can have several reasons:
- the model is not identifiable.
- the optimization routine did not managed to find a local
  optimum. This may happen for complex latent variable model where the
  objective function is not convex or locally convex.
- the user has made a mistake when defining the model or has not given
  the appropriate dataset.

The =checkData= function enables to check the last point. It compares
the observed variables defined in the model and the one given by the
dataset. In case of mismatch it returns a message:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
checkData(mWrong, df.data)
#+END_SRC

#+RESULTS:
: Missing variable in data: X
 
In presence of latent variables, the user needs to explicitely define
them in the model, otherwise =checkData= will identify them as an
issue:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
## simulate data
set.seed(10)
mSim <- lvm(c(Y1,Y2,Y3)~eta)
latent(mSim) <- ~eta
df.data <- sim(mSim, n = 1e2, latent = FALSE)

## fit model
m <- lvm(c(Y1,Y2,Y3)~eta)
checkData(m, data = df.data)
#+END_SRC

#+RESULTS:
: Missing variable in data: eta

#+BEGIN_SRC R :exports both :results output :session *R* :cache no
latent(m) <- ~eta
checkData(m, data = df.data)
#+END_SRC

#+RESULTS:
: No issue detected


** Information about the R session used for this document
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
sessionInfo()
#+END_SRC

#+RESULTS:
#+begin_example
R version 3.4.0 (2017-04-21)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 7 x64 (build 7601) Service Pack 1

Matrix products: default

locale:
[1] LC_COLLATE=Danish_Denmark.1252  LC_CTYPE=Danish_Denmark.1252    LC_MONETARY=Danish_Denmark.1252 LC_NUMERIC=C                   
[5] LC_TIME=Danish_Denmark.1252    

attached base packages:
[1] tcltk     parallel  stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
 [1] testthat_1.0.2            riskRegression_2017.11.15 prodlim_1.6.1             data.table_1.10.4         pbkrtest_0.4-7            pbapply_1.3-3            
 [7] numDeriv_2016.8-1         lmerTest_2.0-33           lme4_1.1-13               lava.tobit_0.5            mets_1.2.2                timereg_1.9.1            
[13] doParallel_1.0.10         iterators_1.0.8           foreach_1.4.3             clubSandwich_0.2.3        sandwich_2.4-0            reshape2_1.4.2           
[19] nlme_3.1-131              Matrix_1.2-9              ggplot2_2.2.1             multcomp_1.4-6            TH.data_1.0-8             MASS_7.3-47              
[25] survival_2.41-3           mvtnorm_1.0-6             lavaSearch2_1.1.0         lava_1.5.1               

loaded via a namespace (and not attached):
 [1] httr_1.2.1          splines_3.4.0       Formula_1.2-1       latticeExtra_0.6-28 selectr_0.3-1       backports_1.1.0     lattice_0.20-35    
 [8] quantreg_5.33       digest_0.6.12       RColorBrewer_1.1-2  checkmate_1.8.2     rvest_0.3.2         minqa_1.2.4         colorspace_1.3-2   
[15] rms_5.1-1           cmprsk_2.2-7        pipeR_0.6.1.3       htmltools_0.3.6     plyr_1.8.4          XML_3.98-1.7        devtools_1.13.2    
[22] SparseM_1.77        scales_0.4.1        MatrixModels_0.4-1  htmlTable_1.9       tibble_1.3.3        withr_1.0.2         nnet_7.3-12        
[29] lazyeval_0.2.0      crayon_1.3.2        magrittr_1.5        polspline_1.1.12    memoise_1.1.0       xml2_1.1.1          foreign_0.8-67     
[36] butils.base_1.1     tools_3.4.0         stringr_1.2.0       munsell_0.4.3       cluster_2.0.6       compiler_3.4.0      rlang_0.1.1        
[43] grid_3.4.0          nloptr_1.0.4        htmlwidgets_0.8     base64enc_0.1-3     gtable_0.2.0        codetools_0.2-15    abind_1.4-5        
[50] roxygen2_6.0.1      R6_2.2.1            gridExtra_2.2.1     zoo_1.8-0           knitr_1.16          commonmark_1.2      Hmisc_4.0-3        
[57] stringi_1.1.5       Rcpp_0.12.11        rpart_4.1-11        acepack_1.4.1
#+end_example
