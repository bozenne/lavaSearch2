#+BEGIN_HTML
<a href="https://travis-ci.org/bozenne/lavaSearch2"><img src="https://travis-ci.org/bozenne/lavaSearch2.svg?branch=master"></a>
<a href="http://cran.rstudio.com/web/packages/lavaSearch2/index.html"><img src="http://www.r-pkg.org/badges/version/lavaSearch2"></a>
<a href="http://cranlogs.r-pkg.org/downloads/total/last-month/lavaSearch2"><img src="http://cranlogs.r-pkg.org/badges/lavaSearch2"></a>
#+END_HTML

* lavaSeach2

*lavaSearch2* is a package for the R software
(https://www.r-project.org/) containing diagnostic and inference tools
for Latent Variable Models (LVM) estimated by maximum likelihood
(ML). It is built upon the *lava* package (see
[[https://github.com/kkholst/lava]]): the *lava* package is used to define
and estimate LVM. While *lava* can also be used to perform diagnostics
and inference, *lavaSearch2* improves some of the existing tools
in *lava*:
- Better control of the type 1 error rate when performing inference
  with small samples. The new methods =summary2= and =compare2=
  replace the =summary= and =compare= functions that performs,
  respectively, univariate and multivariate Wald tests. The new
  methods are also applicable to specific =gls= and =lme= models
  (*nlme* package).
- Better control of the type 1 error rate when adjusting for multiple
  comparisons with small samples (via the *multcomp*
  package). Compared to =glht=, the function =glht2= propagates small
  sample corrections to *multcomp*.
- Better detection of local dependencies that are not included in the
  LVM. The new method =modelsearch2= improves the =modelsearch= method
  by providing p-values adjusted for multiple comparisons. Also
  applicable to Cox models via the libraries *riskRegression* and
  *survival* / *rms*.

_Limitations_: *lavaSearch2* has been design for Gaussian linear
latent variable models. This means that it may not work / give valid
results:
- in presence of censored or binary outcomes.
- with stratified models (i.e. object of class =multigroup=).

 This last case could probably be fixed, you can contact the package
  maintainer if you need this functionality. 

* Installation of lavaSearch2
Install the stable version from CRAN using:
#+BEGIN_SRC R :exports code :results output :session *R* :cache no
install.packages("lavaSearch2")
#+END_SRC

or install the development version from Github using:
#+BEGIN_SRC R :exports code :results output :session *R* :cache no
devtools::install_github("bozenne/lavaSearch2")
#+END_SRC

* Functionalities

Load *lavaSearch2* in the R session:
#+BEGIN_SRC R :exports code :results output :session *R* :cache no
suppressPackageStartupMessages(library(lavaSearch2))
#+END_SRC 

#+RESULTS:


** Inference: single univariate Wald test

*** Introductory example
You may have noticed that for simple linear regression, the p-values
of the Wald tests from =lm=:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
## simulate data
mSim <- lvm(Y[1:1]~0.3*X1+0.2*X2)
set.seed(10)
df.data <- sim(mSim, 2e1)

## fit linear model
summary(lm(Y~X1+X2, data = df.data))$coef
#+END_SRC

#+RESULTS:
:              Estimate Std. Error   t value    Pr(>|t|)
: (Intercept) 0.7967775  0.2506767 3.1785069 0.005495832
: X1          0.1550938  0.2205080 0.7033477 0.491360483
: X2          0.4581556  0.2196785 2.0855736 0.052401103

differ from those obtained with lava:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
## fit latent variable model
m <- lvm(Y~X1+X2)
e <- estimate(m, data = df.data)

## extract Wald tests
summary(e)$coef
#+END_SRC

#+RESULTS:
:       Estimate Std. Error   Z-value      P-value
: Y~X1 0.1550938  0.2032984 0.7628877 0.4455303456
: Y~X2 0.4581556  0.2025335 2.2621221 0.0236898575
: Y~~Y 0.5557910  0.1757566 3.1622777           NA
: Y    0.7967775  0.2311125 3.4475747 0.0005656439

For instance, the p-value for the effect of X2 is 0.024 according to
lava and 0.052 according to =lm=. The discrepancy is due to 2
corrections that =lm= applies in order to improve the control of the
type 1 error of the Wald tests:
- use of a student distribution instead of a normal distribution
  (informally t-value instead of z-value).
- use of a bias-corrected estimator of the residuals variance instead
  of the ML-estimator.
*lavaSearch2* attempts to generalize these corrections to models with
correlated and heteroschedastic measurements. In the case of a simple
linear regression, Wald tests obtained with *lavaSearch2* closely
approximate the results of =lm=:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
summary2(e)$coef
#+END_SRC

#+RESULTS:
:       Estimate Std. Error   t-value    P-value    df
: Y~X1 0.1550938  0.2205078 0.7033483 0.49136012 17.00
: Y~X2 0.4581556  0.2196783 2.0855754 0.05240092 17.00
: Y~~Y 0.5557910  0.2242758 2.4781588         NA  4.25
: Y    0.7967775  0.2506765 3.1785096 0.00549580 17.00

*** How it works in a nutshell

When using *lava*, the p.values that are obtained from the summary
(Wald tests) rely on a Gaussian approximation. While being
asymptotically valid, this approximation may not provide a very
accurate control of the type 1 error rate in small
samples. Simulations have shown that the type 1 error rate tends to be
too large, i.e. the p.values are have a downward bias.  gg
*lavaSearch2* improves the Gaussian approximation in two way:
- using a Student's t distribution instead of a normal distribution to
  account for the uncertainty on the variance of the coefficients. The
  degrees of freedom are estimated using Satterwaite approximation,
  i.e. identifying the chi-squared distribution that best fit the
  observed moments of the variance of the coefficients. 
- correct for the first order bias in the residual variance due to ML
  estimation. This bias also affects the standard error of the
  estimates and the control of the type 1 error. The correction does
  not change the estimates (i.e. the column "Estimate" in the summary
  remain unchanged), but it changes the corresponding standard error
  and degree of freedoms (i.e. columns "Std. Error" and "df" in the
  summary are modified).

*** Example

We will illustrate the functionalities using a simulated dataset:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
## simulate data
mSim <- lvm(Y1~eta,Y2~eta,Y3~0.4+0.4*eta,Y4~0.6+0.6*eta,eta~0.5*X1+0.7*X2)
latent(mSim) <- ~eta
set.seed(12)
df.data <- sim(mSim, n = 3e1, latent = FALSE)

## display
head(df.data)
#+END_SRC

#+RESULTS:
:           Y1         Y2          Y3         Y4         X1         X2
: 1 -1.7606233  0.1264910  0.66442611  0.2579355  0.2523400 -1.5431527
: 2  3.0459417  2.4631929  0.00283511  2.1714802  0.6423143 -1.3206009
: 3 -2.1443162 -0.3318033  0.82253070  0.3008415 -0.3469361 -0.6758215
: 4 -2.5050328 -1.3878987 -0.10474850 -1.7814956 -0.5152632 -0.3670054
: 5 -2.5307249  0.3012422  1.22046986 -1.0195188  0.3981689 -0.5138722
: 6 -0.9521366  0.1669496 -0.21422548  1.5954456  0.9535572 -0.9592540

We first fit the latent variable model using, as usual, the =estimate=
function:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
m <- lvm(c(Y1,Y2,Y3,Y4)~eta, eta~X1+X2)
e <- estimate(m, data = df.data)
#+END_SRC

#+RESULTS:

We can extract the Wald tests based on a normal approximation using
=summary=:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
summary(e)$coef[c("Y2","Y3","Y2~eta","Y3~eta","eta~X1","eta~X2"), ]
#+END_SRC

#+RESULTS:
:         Estimate Std. Error   Z-value      P-value
: Y2     0.2335412  0.2448593 0.9537775 0.3401962906
: Y3     0.5114275  0.1785886 2.8637186 0.0041869974
: Y2~eta 0.9192847  0.2621248 3.5070497 0.0004531045
: Y3~eta 0.2626930  0.1558978 1.6850339 0.0919820326
: eta~X1 0.5150072  0.2513393 2.0490515 0.0404570768
: eta~X2 0.6212222  0.2118930 2.9317729 0.0033703310

As explain at the begining of this section, *lavaSearch2* implements
two corrections that can be directly applied by calling the =summary2=
method:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
summary2(e)$coef[c("Y2","Y3","Y2~eta","Y3~eta","eta~X1","eta~X2"), ]
#+END_SRC

#+RESULTS:
:         Estimate Std. Error  t-value     P-value        df
: Y2     0.2335412  0.2527207 0.924108 0.374106825 11.693277
: Y3     0.5114275  0.1837183 2.783760 0.010427333 23.512785
: Y2~eta 0.9192847  0.2745366 3.348496 0.038240130  3.301380
: Y3~eta 0.2626930  0.1668141 1.574765 0.172134170  5.368341
: eta~X1 0.5150072  0.2648115 1.944807 0.066048507 19.926275
: eta~X2 0.6212222  0.2231418 2.783979 0.009477757 28.225589

To use the Satterthwaite correction alone, set the argument
  =bias.correct= to =FALSE=:

#+BEGIN_SRC R :exports both :results output :session *R* :cache no
summary2(e, bias.correct = FALSE)$coef[c("Y2","Y3","Y2~eta","Y3~eta","eta~X1","eta~X2"), ]
#+END_SRC

#+RESULTS:
:         Estimate Std. Error   t-value     P-value        df
: Y2     0.2335412  0.2448593 0.9537775 0.357711941 12.911877
: Y3     0.5114275  0.1785886 2.8637186 0.008210968 25.780552
: Y2~eta 0.9192847  0.2621248 3.5070497 0.028396459  3.674640
: Y3~eta 0.2626930  0.1558978 1.6850339 0.141185621  6.222912
: eta~X1 0.5150072  0.2513393 2.0490515 0.052814794 21.571210
: eta~X2 0.6212222  0.2118930 2.9317729 0.006351686 30.370334

When using the Satterthwaite correction alone, the standard error are
left unchanged compared to the original lava output. The only change
is how the p-values are computed, i.e. based on the quantiles of a
Student's t distribution instead of a Gaussian distribution. 

*** Saving computation time with =sCorrect=
For each call to =summary2= the small sample size correction(s) will
be recalculated. However the calculation of the sample correction(s)
can be time consuming.
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
system.time(
    res <- summary2(e, bias.correct = FALSE)
)
#+END_SRC

#+RESULTS:
:    user  system elapsed 
:    0.17    0.00    0.18

In such a case one can pre-compute the main terms of the correction
(e.g. the derivative of the variance-covariance matrix) once for all
using the =sCorrect= method (=sCorrect= stands for Satterthwaite
correction). When calling =sCorrect=, the right hand side indicates
whether the bias correction should be used (equivalent to
=bias.correct= argument described previously):
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
e2 <- e
sCorrect(e2) <- TRUE
#+END_SRC

#+RESULTS:

=sCorrect= automatically store the pre-computed terms in the =sCorrect=
slot of the object. It also adds the class =lvmfit2= to the object:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
class(e2)
#+END_SRC
#+RESULTS:
: [1] "lvmfit2" "lvmfit"

Then p-values computed using the small sample correction can be
obtained calling the =summary= method, as usual:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
summary2(e2)$coef[c("Y2","Y3","Y2~eta","Y3~eta","eta~X1","eta~X2"), ]
#+END_SRC

#+RESULTS:
:         Estimate Std. Error  t-value     P-value        df
: Y2     0.2335412  0.2527207 0.924108 0.374106825 11.693277
: Y3     0.5114275  0.1837183 2.783760 0.010427333 23.512785
: Y2~eta 0.9192847  0.2745366 3.348496 0.038240130  3.301380
: Y3~eta 0.2626930  0.1668141 1.574765 0.172134170  5.368341
: eta~X1 0.5150072  0.2648115 1.944807 0.066048507 19.926275
: eta~X2 0.6212222  0.2231418 2.783979 0.009477757 28.225589

The =summary2= methods take approximately the same time as the usual
=summary= method:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
system.time(
    summary2(e2)
)
#+END_SRC

#+RESULTS:
:    user  system elapsed 
:    0.11    0.00    0.10

#+BEGIN_SRC R :exports both :results output :session *R* :cache no
system.time(
    summary(e2)
)
#+END_SRC

#+RESULTS:
:    user  system elapsed 
:    0.10    0.00    0.09

** Inference: single multivariate Wald test

The function =compare= can be use to perform multivariate Wald tests,
i.e. to test simultaneously several linear combinations of the
coefficients.  =compare= uses a contrast matrix to encode in lines
which linear combination of coefficients should be tested. For
instance if we want to simultaneously test whether all the mean
coefficients are 0, we can create a contrast matrix using
=createContrast=:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
resC <- createContrast(e2, par = c("Y2=0","Y2~eta=0","eta~X1=0"))
resC
#+END_SRC

#+RESULTS:
#+begin_example
$contrast
             Y2 Y3 Y4 eta Y2~eta Y3~eta Y4~eta eta~X1 eta~X2 Y1~~Y1 Y2~~Y2 Y3~~Y3 Y4~~Y4 eta~~eta
[Y2] = 0      1  0  0   0      0      0      0      0      0      0      0      0      0        0
[Y2~eta] = 0  0  0  0   0      1      0      0      0      0      0      0      0      0        0
[eta~X1] = 0  0  0  0   0      0      0      0      1      0      0      0      0      0        0

$null
    [Y2] = 0 [Y2~eta] = 0 [eta~X1] = 0 
           0            0            0 

$Q
[1] 3
#+end_example

We can then test the linear hypothesis by specifying in =compare= the
left hand side of the hypothesis (argument contrast) and the right
hand side (argument null):
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
resTest0 <- lava::compare(e2, contrast = resC$contrast, null = resC$null)
resTest0
#+END_SRC

#+RESULTS:
#+begin_example

	- Wald test -

	Null Hypothesis:
	[Y2] = 0
	[Y2~eta] = 0
	[eta~X1] = 0

data:  
chisq = 21.332, df = 3, p-value = 8.981e-05
sample estimates:
          Estimate   Std.Err       2.5%     97.5%
[Y2]     0.2335412 0.2448593 -0.2463741 0.7134566
[Y2~eta] 0.9192847 0.2621248  0.4055295 1.4330399
[eta~X1] 0.5150072 0.2513393  0.0223912 1.0076231
#+end_example

=compare= uses a chi-squared distribution to compute the p-values.
Similarly to the Gaussian approximation, while being valid
asymptotically this procedure may not provide a very accurate control
of the type 1 error rate in small samples. Fortunately, the correction
proposed for the univariate Wald statistic can be adapted to the
multivariate Wald statistic. This is achieved by =compare2=:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
resTest1 <- compare2(e2, contrast = resC$contrast, null = resC$null)
resTest1
#+END_SRC

#+RESULTS:
#+begin_example

	- Wald test -

	Null Hypothesis:
	[Y2] = 0
	[Y2~eta] = 0
	[eta~X1] = 0

data:  
F-statistic = 6.4421, df1 = 3, df2 = 9.82, p-value = 0.01091
sample estimates:
              Estimate   Std.Err       df        2.5%     97.5%
[Y2] = 0     0.2335412 0.2527207 11.69328 -0.31869611 0.7857786
[Y2~eta] = 0 0.9192847 0.2745366  3.30138  0.08901989 1.7495495
[eta~X1] = 0 0.5150072 0.2648115 19.92628 -0.03751095 1.0675253
#+end_example

The same result could have been obtained using the par argument to
define the linear hypothesis:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
resTest2 <- compare2(e2, par = c("Y2","Y2~eta","eta~X1"))
identical(resTest1,resTest2)
#+END_SRC

#+RESULTS:
: [1] TRUE

Now a F distribution is used to compute the p-values. As before on can
set the argument =bias.correct= to =FALSE= to use the Satterthwaite
approximation alone:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
resTest3 <- compare2(e, bias.correct = FALSE, 
                      contrast = resC$contrast, null = resC$null)
resTest3
#+END_SRC

#+RESULTS:
#+begin_example

	- Wald test -

	Null Hypothesis:
	[Y2] = 0
	[Y2~eta] = 0
	[eta~X1] = 0

data:  
F-statistic = 7.1107, df1 = 3, df2 = 11.13, p-value = 0.006182
sample estimates:
              Estimate   Std.Err       df         2.5%     97.5%
[Y2] = 0     0.2335412 0.2448593 12.91188 -0.295812256 0.7628948
[Y2~eta] = 0 0.9192847 0.2621248  3.67464  0.165378080 1.6731913
[eta~X1] = 0 0.5150072 0.2513393 21.57121 -0.006840023 1.0368543
#+end_example

In this case the F-statistic of =compare2= is the same as the
chi-squared statistic of =compare= divided by the rank of the contrast matrix:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
resTest0$statistic/qr(resC$contrast)$rank
#+END_SRC

#+RESULTS:
:    chisq 
: 7.110689

** Inference: robust Wald tests

When one does not want to assume normality distributed residuals,
robust standard error can be used instead of the model based standard
errors. They can be obtain by setting the argument =robust= to =TRUE=
when computing univariate Wald tests:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
summary2(e, robust = TRUE)$coef[c("Y2","Y3","Y2~eta","Y3~eta","eta~X1","eta~X2"), ]
#+END_SRC

#+RESULTS:
:         Estimate Std. Error   t-value     P-value        df
: Y2     0.2335412  0.2350305 0.9936635 0.340504442 11.693277
: Y3     0.5114275  0.1901691 2.6893308 0.012947284 23.512785
: Y2~eta 0.9192847  0.1873461 4.9068791 0.012905321  3.301380
: Y3~eta 0.2626930  0.1449546 1.8122432 0.125677849  5.368341
: eta~X1 0.5150072  0.2192081 2.3493981 0.029228312 19.926275
: eta~X2 0.6212222  0.2013996 3.0845261 0.004528349 28.225589

or multivariate Wald test:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
compare2(e2, robust = TRUE, par = c("Y2","Y2~eta","eta~X1"))
#+END_SRC

#+RESULTS:
#+begin_example

	- Wald test -

	Null Hypothesis:
	[Y2] = 0
	[Y2~eta] = 0
	[eta~X1] = 0

data:  
F-statistic = 11.089, df1 = 3, df2 = 9.82, p-value = 0.001699
sample estimates:
              Estimate   Std.Err       df        2.5%     97.5%
[Y2] = 0     0.2335412 0.2350305 11.69328 -0.28004000 0.7471225
[Y2~eta] = 0 0.9192847 0.1873461  3.30138  0.35270497 1.4858644
[eta~X1] = 0 0.5150072 0.2192081 19.92628  0.05763853 0.9723758
#+end_example

Only the standard error is affected by the argument =robust=, the
degrees of freedom are the one of the model-based standard errors.  It
may be surprising that the (corrected) robust standard errors are (in
this example) smaller than the (corrected) model-based one. This is
also the case for the uncorrected one:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
rbind(robust = diag(crossprod(iid(e2))),
      model = diag(vcov(e2)))
#+END_SRC

#+RESULTS:
:                Y2         Y3         Y4        eta     Y2~eta     Y3~eta     Y4~eta     eta~X1     eta~X2    Y1~~Y1    Y2~~Y2     Y3~~Y3     Y4~~Y4  eta~~eta
: robust 0.04777252 0.03325435 0.03886706 0.06011727 0.08590732 0.02179453 0.02981895 0.05166005 0.05709393 0.2795272 0.1078948 0.03769614 0.06923165 0.3198022
: model  0.05995606 0.03189389 0.04644303 0.06132384 0.06870941 0.02430412 0.03715633 0.06317144 0.04489865 0.1754744 0.1600112 0.05112998 0.10152642 0.2320190

This may be explained by the fact the robust standard error tends to
be liberal in small samples (e.g. see Kauermann 2001, A Note on the
Efficiency of Sandwich Covariance Matrix Estimation ).
** Inference: assessing the type 1 error of the testing procedure

The function =calibrateType1= can be used to assess the type 1 error
of a Wald statistic on a specific example. This however assumes that
the estimated model is correctly specified. Let's make an example. For
this we simulate some data:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
set.seed(10)
m.generative <- lvm(Y ~ X1 + X2 + Gene)
categorical(m.generative, labels = c("ss","ll")) <- ~Gene
d <- lava::sim(m.generative, n = 50, latent = FALSE)
#+END_SRC

#+RESULTS:

Let's now imagine that we want to analyze the relationship between
Y and Gene using the following dataset:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
head(d)
#+END_SRC

#+RESULTS:
:             Y         X1         X2 Gene
: 1 -1.14369572 -0.4006375 -0.7618043   ss
: 2 -0.09943370 -0.3345566  0.4193754   ss
: 3 -0.04331996  1.3679540 -1.0399434   ll
: 4  2.25017335  2.1377671  0.7115740   ss
: 5  0.16715138  0.5058193 -0.6332130   ss
: 6  1.73931135  0.7863424  0.5631747   ss

For this we fit define a LVM:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
myModel <- lvm(Y ~ X1 + X2 + Gene)
#+END_SRC

#+RESULTS:

and estimate the coefficients of the model using =estimate=:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
e <- estimate(myModel, data = d)
e
#+END_SRC
#+RESULTS:
:                     Estimate Std. Error  Z-value  P-value
: Regressions:                                             
:    Y~X1              1.02349    0.12017  8.51728   <1e-12
:    Y~X2              0.91519    0.12380  7.39244   <1e-12
:    Y~Genell          0.48035    0.23991  2.00224  0.04526
: Intercepts:                                              
:    Y                -0.11221    0.15773 -0.71141   0.4768
: Residual Variances:                                      
:    Y                 0.67073    0.13415  5.00000

We can now use =calibrateType1= to perform a simulation study. We just
need to define the null hypotheses (i.e. which coefficient should be
set to 0 when generating the data) and the number of simulations:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
mySimulation <- calibrateType1(e, 
                               null = "Y~Genell",
                               n.rep = 50, 
                               trace = FALSE, seed = 10)
#+END_SRC

#+RESULTS:
To save time we only make 50 simulations but much more are necessary
to really assess the type 1 error rate. Then we can use the =summary=
method to display the results:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
summary(mySimulation)
#+END_SRC

#+RESULTS:
: Estimated type 1 error rate [95% confidence interval] 
:   > sample size: 50 | number of simulations: 50
:                                                        link statistic type1error                  CI
: Gaussian approx.                                   Y~Genell      Wald       0.12 [0.05492 ; 0.24242]
: Satterthwaite approx.                                                       0.10 [0.04224 ; 0.21869]
: small sample correction                                                     0.10 [0.04224 ; 0.21869]
: Satterthwaite approx. with small sample correction                          0.08 [0.03035 ; 0.19456]


** Adjustment for multiple comparisons: univariate Wald test, single model

When performing multiple testing, adjustment for multiple comparisons
is necessary in order to control the type 1 error rate, i.e. to
provide interpretable p.values. The *multcomp* package enables to do
such adjustment when all tests comes from the same =lvmfit= object:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
suppressPackageStartupMessages(library(multcomp))

## simulate data
mSim <- lvm(Y ~ 0.25 * X1 + 0.3 * X2 + 0.35 * X3 + 0.4 * X4 + 0.45 * X5 + 0.5 * X6)
set.seed(10)
df.data <- sim(mSim, n = 4e1)

## fit lvm
e.lvm <- estimate(lvm(Y ~ X1 + X2 + X3 + X4 + X5 + X6), data = df.data)
name.coef <- names(coef(e.lvm))
n.coef <- length(name.coef)

## Create contrast matrix
resC <- createContrast(e.lvm, par = paste0("Y~X",1:6), rowname.rhs = FALSE)
resC$contrast
#+END_SRC

#+RESULTS:
:      Y Y~X1 Y~X2 Y~X3 Y~X4 Y~X5 Y~X6 Y~~Y
: Y~X1 0    1    0    0    0    0    0    0
: Y~X2 0    0    1    0    0    0    0    0
: Y~X3 0    0    0    1    0    0    0    0
: Y~X4 0    0    0    0    1    0    0    0
: Y~X5 0    0    0    0    0    1    0    0
: Y~X6 0    0    0    0    0    0    1    0

#+BEGIN_SRC R :exports both :results output :session *R* :cache no
e.glht <- glht(e.lvm, linfct = resC$contrast, rhs = resC$null)
summary(e.glht)
#+END_SRC
#+RESULTS:
#+begin_example

	 Simultaneous Tests for General Linear Hypotheses

Fit: estimate.lvm(x = lvm(Y ~ X1 + X2 + X3 + X4 + X5 + X6), data = df.data)

Linear Hypotheses:
          Estimate Std. Error z value Pr(>|z|)   
Y~X1 == 0   0.3270     0.1589   2.058  0.20725   
Y~X2 == 0   0.4025     0.1596   2.523  0.06611 . 
Y~X3 == 0   0.5072     0.1383   3.669  0.00144 **
Y~X4 == 0   0.3161     0.1662   1.902  0.28582   
Y~X5 == 0   0.3875     0.1498   2.586  0.05554 . 
Y~X6 == 0   0.3758     0.1314   2.859  0.02482 * 
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
(Adjusted p values reported -- single-step method)
#+end_example

Note that this correction relies on the Gaussian approximation. To use
small sample corrections implemented in *lavaSearch2*, just call
=glht2= instead of =glht=:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
e.glht2 <- glht2(e.lvm, linfct = resC$contrast, rhs = resC$null)
summary(e.glht2)
#+END_SRC

#+RESULTS:
#+begin_example

	 Simultaneous Tests for General Linear Hypotheses

Fit: estimate.lvm(x = lvm(Y ~ X1 + X2 + X3 + X4 + X5 + X6), data = df.data)

Linear Hypotheses:
          Estimate Std. Error t value Pr(>|t|)  
Y~X1 == 0   0.3270     0.1750   1.869   0.3290  
Y~X2 == 0   0.4025     0.1757   2.291   0.1482  
Y~X3 == 0   0.5072     0.1522   3.333   0.0123 *
Y~X4 == 0   0.3161     0.1830   1.727   0.4128  
Y~X5 == 0   0.3875     0.1650   2.349   0.1315  
Y~X6 == 0   0.3758     0.1447   2.597   0.0762 .
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
(Adjusted p values reported -- single-step method)
#+end_example

The single step method is the appropriate correction when one wants to
report the most significant p-value relative to a set of
hypotheses. If the second most significant p-value is also to be
reported then the method "free" is more appropriate:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
summary(e.glht2, test = adjusted("free"))
#+END_SRC

#+RESULTS:
#+begin_example

	 Simultaneous Tests for General Linear Hypotheses

Fit: estimate.lvm(x = lvm(Y ~ X1 + X2 + X3 + X4 + X5 + X6), data = df.data)

Linear Hypotheses:
          Estimate Std. Error t value Pr(>|t|)  
Y~X1 == 0   0.3270     0.1750   1.869   0.1291  
Y~X2 == 0   0.4025     0.1757   2.291   0.0913 .
Y~X3 == 0   0.5072     0.1522   3.333   0.0123 *
Y~X4 == 0   0.3161     0.1830   1.727   0.1291  
Y~X5 == 0   0.3875     0.1650   2.349   0.0913 .
Y~X6 == 0   0.3758     0.1447   2.597   0.0645 .
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
(Adjusted p values reported -- free method)
#+end_example
Indeed, here there is no relations between the hypotheses. See the
book: "Multiple Comparisons Using R" by Frank Bretz, Torsten Hothorn,
and Peter Westfall (2011, CRC Press) for details about the theory
underlying the *multcomp* package.

** Adjustment for multiple comparisons: univariate Wald test, multiple models

Pipper et al. in "A Versatile Method for Confirmatory Evaluation of
the Effects of a Covariate in Multiple Models" (2012, Journal of the
Royal Statistical Society, Series C) developed a method to assess the
effect of an exposure on several outcomes when a different model is
fitted for each outcome. This method has been implemented in the =mmm=
function from the *multcomp* package for glm and Cox
models. *lavaSearch2* extends it to =lvm=. 

Let's consider an example where we wish to assess the treatment effect
on three outcomes X, Y, and Z. We have at hand three measurements
relative to outcome Z for each individual:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
mSim <- lvm(X ~ Age + 0.5*Treatment,
            Y ~ Gender + 0.25*Treatment,
            c(Z1,Z2,Z3) ~ eta, eta ~ 0.75*treatment,
            Age[40:5]~1)
latent(mSim) <- ~eta
categorical(mSim, labels = c("placebo","SSRI")) <- ~Treatment
categorical(mSim, labels = c("male","female")) <- ~Gender

n <- 5e1
set.seed(10)
df.data <- sim(mSim, n = n, latent = FALSE)
head(df.data)
#+END_SRC

#+RESULTS:
:          X      Age Treatment          Y Gender         Z1         Z2          Z3  treatment
: 1 39.12289 39.10415   placebo  0.6088958 female  1.8714112  2.2960633 -0.09326935  1.1639675
: 2 39.56766 39.25191      SSRI  1.0001325 female  0.9709943  0.6296226  1.31035910 -1.5233846
: 3 41.68751 43.05884   placebo  2.1551047 female -1.1634011 -0.3332927 -1.30769267 -2.5183351
: 4 44.68102 44.78019      SSRI  0.3852728 female -1.0305476  0.6678775  0.99780139 -0.7075292
: 5 41.42559 41.13105   placebo -0.8666783   male -1.6342816 -0.8285492  1.20450488 -0.2874329
: 6 42.64811 41.75832      SSRI -1.0710170 female -1.2198019 -1.9602130 -1.85472132 -0.4353083

We fit a model specific to each outcome:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
lmX <- lm(X ~ Age + Treatment, data = df.data)
lvmY <- estimate(lvm(Y ~ Gender + Treatment), data = df.data)
lvmZ <- estimate(lvm(c(Z1,Z2,Z3) ~ 1*eta, eta ~ -1 + Treatment), 
                 data = df.data)
#+END_SRC

#+RESULTS:

and combine them into a list of =lvmfit= objects:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
mmm.lvm <- mmm(X = lmX, Y = lvmY, Z = lvmZ)
#+END_SRC

#+RESULTS:

We can then generate a contrast matrix to test each coefficient
related to the treatment:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
resC <- createContrast(mmm.lvm, var.test = "Treatment", add.variance = TRUE)
resC$contrast
#+END_SRC

#+RESULTS:
:                      X: (Intercept) X: Age X: TreatmentSSRI X: sigma2 Y: Y Y: Y~Genderfemale Y: Y~TreatmentSSRI Y: Y~~Y Z: Z1 Z: Z2 Z: Z3 Z: eta~TreatmentSSRI
: X: TreatmentSSRI                  0      0                1         0    0                 0                  0       0     0     0     0                    0
: Y: Y~TreatmentSSRI                0      0                0         0    0                 0                  1       0     0     0     0                    0
: Z: eta~TreatmentSSRI              0      0                0         0    0                 0                  0       0     0     0     0                    1
:                      Z: Z1~~Z1 Z: Z2~~Z2 Z: Z3~~Z3 Z: eta~~eta
: X: TreatmentSSRI             0         0         0           0
: Y: Y~TreatmentSSRI           0         0         0           0
: Z: eta~TreatmentSSRI         0         0         0           0

#+BEGIN_SRC R :exports both :results output :session *R* :cache no
lvm.glht2 <- glht2(mmm.lvm, linfct = resC$contrast, rhs = resC$null)
summary(lvm.glht2)
#+END_SRC

#+RESULTS:
: 
: 	 Simultaneous Tests for General Linear Hypotheses
: 
: Linear Hypotheses:
:                           Estimate Std. Error t value Pr(>|t|)
: X: TreatmentSSRI == 0       0.4661     0.2533   1.840    0.187
: Y: Y~TreatmentSSRI == 0    -0.5421     0.2613  -2.074    0.117
: Z: eta~TreatmentSSRI == 0  -0.6198     0.4404  -1.407    0.393
: (Adjusted p values reported -- single-step method)

This can be compared to the unadjusted p.values:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
summary(lvm.glht2, test = univariate())
#+END_SRC

#+RESULTS:
#+begin_example

	 Simultaneous Tests for General Linear Hypotheses

Linear Hypotheses:
                          Estimate Std. Error t value Pr(>|t|)  
X: TreatmentSSRI == 0       0.4661     0.2533   1.840   0.0720 .
Y: Y~TreatmentSSRI == 0    -0.5421     0.2613  -2.074   0.0435 *
Z: eta~TreatmentSSRI == 0  -0.6198     0.4404  -1.407   0.1659  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
(Univariate p values reported)
#+end_example

** Model diagnostic: detection of local dependencies

The =modelsearch= function of *lava* is a diagnostic tool for latent
variable models. It enables to search for local dependencies
(i.e. model misspecification) and add them to the model. Obviously it
is a data-driven procedure and its usefulness can be discussed,
especially in small samples:
- the procedure is instable, i.e. is likely to lead to two different
  models when applied on two different dataset sampled from the same
  generative model.
- it is hard to define a meaningful significance threshold since
  p-values should be adjusted for multiple comparisons and sequential
  testing. However traditional methods like Bonferonni-Holm tend to
  over corrected and therefore reduce the power of the procedure since
  they assume that the test are independent.

The function =modelsearch2= in *lavaSearch2* partially solves the
second issue by adjusting the p-values for multiple testing.

Let's see an example:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
## simulate data
mSim <- lvm(c(y1,y2,y3)~u, u~x1+x2)
latent(mSim) <- ~u
covariance(mSim) <- y2~y3
transform(mSim, Id~u) <- function(x){1:NROW(x)}
set.seed(10)
df.data <- lava::sim(mSim, n = 125, latent = FALSE)
head(df.data)
#+END_SRC

#+RESULTS:
:           y1           y2         y3         x1         x2 Id
: 1  5.5071523  4.883752014  6.2928016  0.8694750  2.3991549  1
: 2 -0.6398644  0.025832617  0.5088030 -0.6800096 -0.0898721  2
: 3 -2.5835495 -2.616715027 -2.8982645  0.1732145 -0.8216484  3
: 4 -2.5312637 -2.518185427 -2.9015033 -0.1594380 -0.2869618  4
: 5  1.6346220 -0.001877577  0.3705181  0.7934994  0.1312789  5
: 6  0.4939972  1.759884014  1.5010499  1.6943505 -1.0620840  6

#+BEGIN_SRC R :exports both :results output :session *R* :cache no
## fit model
m <- lvm(c(y1,y2,y3)~u, u~x1)
latent(m) <- ~u
addvar(m) <- ~x2 
e.lvm <- estimate(m, data = df.data)
#+END_SRC

#+RESULTS:

=modelsearch2= can be used to sequentially apply the =modelsearch=
function with a given correction for the p.values:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
resScore <- modelsearch2(e.lvm, statistic = "score", method.p.adjust = "holm",
                         alpha = 0.1, trace = FALSE)
summary(resScore)
#+END_SRC

#+RESULTS:
: Sequential search for local dependence using the score statistic 
:  The variable selection procedure retained 3 variables:
:      link nTests noConvergence statistic adjusted.p.value
: 10   u~x2     10             0 36.436487     1.577228e-08
: 5  y2~~y3      9             0  6.912568     7.703278e-02
: 7   y3~x1      8             0  3.136431     6.124895e-01
: confidence level: 0.9 (two sided, adjustement: holm)

This indeed matches the highest score statistic found by
=modelsearch=:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
resScore0 <- modelsearch(e.lvm, silent = TRUE)
max(resScore0$test[,"Test Statistic"])
#+END_SRC

#+RESULTS:
: [1] 36.43649

To adjust for multiple comparisons, the argument statistic needs to be
set to =Wald=. Setting the argument =method.p.adjust= to =max= enable
an appropriate adjustment of the p.values for multiple comparisons:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
resMax <- modelsearch2(e.lvm, statistic = "Wald", method.p.adjust = "max",
                       alpha = 0.1, trace = FALSE)
summary(resMax)
#+END_SRC

#+RESULTS:
: Sequential search for local dependence using the Wald statistic 
:  The variable selection procedure retained 3 variables:
:      link nTests noConvergence statistic adjusted.p.value quantile
: 10   u~x2     10             0  6.689413     2.542490e-08 2.479380
: 5  y2~~y3      9             0  2.518004     9.324059e-02 2.481149
: 7   y3~x1      8             0  1.789390     2.954362e-01 2.361580
: confidence level: 0.9 (two sided, adjustement: max)

We can compare the adjustment using the max distribution to bonferroni:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
c(bonferroni =  min(p.adjust(resMax$sequenceTest[[2]][,"p.value"], method = "bonferroni")),
  max = min(resMax$sequenceTest[[2]][,"adjusted.p.value"]))
#+END_SRC

#+RESULTS:
: bonferroni        max 
: 0.14713715 0.09324059

Here the difference is small because the generative model did not
include an unknown correlation structure. Because it can be time
consuming to compute the exact p-values, an approximation could be to
only compute them when no p-value passes the bonferroni correction at
a given step. The is what the option =fastmax= does:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
resMax2 <- modelsearch2(e.lvm, statistic = "Wald", method.p.adjust = "fastmax",
                        alpha = 0.1, trace = FALSE)
summary(resMax2)
#+END_SRC

#+RESULTS:
: Sequential search for local dependence using the Wald statistic 
:  The variable selection procedure retained 3 variables:
:      link nTests noConvergence statistic adjusted.p.value
: 10   u~x2     10             0  6.689413       0.00000000
: 5  y2~~y3      9             0  2.518004       0.09315477
: 7   y3~x1      8             0  1.789390       0.29565912
: confidence level: 0.9 (two sided, adjustement: fastmax)

** Model diagnostic: checking that the names of the variables in the model match those of the data

When estimating latent variable models using *lava*, it sometimes
happens that the model does not converge:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
## simulate data
set.seed(10)
df.data <- sim(lvm(Y~X1+X2), 1e2)

## fit model
mWrong <- lvm(Y ~ X + X2)
eWrong <- estimate(mWrong, data = df.data)
#+END_SRC

#+RESULTS:
: Warning messages:
: 1: In estimate.lvm(mWrong, data = df.data) :
:   Lack of convergence. Increase number of iteration or change starting values.
: 2: In sqrt(diag(asVar)) : NaNs produced

 This can have several reasons:
- the model is not identifiable.
- the optimization routine did not managed to find a local
  optimum. This may happen for complex latent variable model where the
  objective function is not convex or locally convex.
- the user has made a mistake when defining the model or has not given
  the appropriate dataset.

The =checkData= function enables to check the last point. It compares
the observed variables defined in the model and the one given by the
dataset. In case of mismatch it returns a message:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
checkData(mWrong, df.data)
#+END_SRC

#+RESULTS:
: Missing variable in data: X
 
In presence of latent variables, the user needs to explicitely define
them in the model, otherwise =checkData= will identify them as an
issue:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
## simulate data
set.seed(10)
mSim <- lvm(c(Y1,Y2,Y3)~eta)
latent(mSim) <- ~eta
df.data <- sim(mSim, n = 1e2, latent = FALSE)

## fit model
m <- lvm(c(Y1,Y2,Y3)~eta)
checkData(m, data = df.data)
#+END_SRC

#+RESULTS:
: Missing variable in data: eta

#+BEGIN_SRC R :exports both :results output :session *R* :cache no
latent(m) <- ~eta
checkData(m, data = df.data)
#+END_SRC

#+RESULTS:
: No issue detected


* Information about the R session used for this document
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
sessionInfo()
#+END_SRC

#+RESULTS:
#+begin_example
R version 3.4.0 (2017-04-21)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 7 x64 (build 7601) Service Pack 1

Matrix products: default

locale:
[1] LC_COLLATE=Danish_Denmark.1252  LC_CTYPE=Danish_Denmark.1252    LC_MONETARY=Danish_Denmark.1252 LC_NUMERIC=C                   
[5] LC_TIME=Danish_Denmark.1252    

attached base packages:
[1] tcltk     parallel  stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
 [1] lavaSearch2_1.3.0         riskRegression_2018.02.20 prodlim_1.6.1             pbapply_1.3-3             numDeriv_2016.8-1         doParallel_1.0.10        
 [7] iterators_1.0.8           foreach_1.4.3             sandwich_2.4-0            reshape2_1.4.2            multcomp_1.4-6            TH.data_1.0-8            
[13] MASS_7.3-47               ggplot2_2.2.1             lava.tobit_0.5            mvtnorm_1.0-6             mets_1.2.2                timereg_1.9.1            
[19] survival_2.41-3           data.table_1.10.4         pbkrtest_0.4-7            lmerTest_2.0-37.90016     lme4_1.1-13               Matrix_1.2-9             
[25] nlme_3.1-131              clubSandwich_0.2.3        lava_1.5.1                testthat_2.0.0            spelling_1.1              roxygen2_6.0.1           
[31] butils.base_1.1           XML_3.98-1.7              selectr_0.3-1             devtools_1.13.2          

loaded via a namespace (and not attached):
 [1] cmprsk_2.2-7        rms_5.1-1           RColorBrewer_1.1-2  httr_1.2.1          rprojroot_1.2       tools_3.4.0         backports_1.1.0    
 [8] R6_2.2.1            rpart_4.1-11        Hmisc_4.0-3         lazyeval_0.2.0      colorspace_1.3-2    nnet_7.3-12         withr_2.1.2        
[15] gridExtra_2.2.1     curl_2.6            git2r_0.18.0        compiler_3.4.0      cli_1.0.0           rvest_0.3.2         quantreg_5.33      
[22] htmlTable_1.9       SparseM_1.77        xml2_1.1.1          desc_1.1.0          scales_0.4.1        checkmate_1.8.2     polspline_1.1.12   
[29] commonmark_1.2      stringr_1.2.0       digest_0.6.12       foreign_0.8-67      minqa_1.2.4         pipeR_0.6.1.3       base64enc_0.1-3    
[36] htmltools_0.3.6     htmlwidgets_0.8     rlang_0.1.1         zoo_1.8-0           acepack_1.4.1       magrittr_1.5        Formula_1.2-1      
[43] Rcpp_0.12.11        munsell_0.4.3       abind_1.4-5         stringi_1.1.5       plyr_1.8.4          grid_3.4.0          crayon_1.3.4       
[50] lattice_0.20-35     splines_3.4.0       knitr_1.16          codetools_0.2-15    latticeExtra_0.6-28 nloptr_1.0.4        MatrixModels_0.4-1 
[57] gtable_0.2.0        assertthat_0.2.0    tibble_1.3.3        memoise_1.1.0       cluster_2.0.6
#+end_example
